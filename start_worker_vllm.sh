#!/usr/bin/env bash
set -euo pipefail

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# DGX Spark vLLM Worker Node - Production Setup Script
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# NOTE: This script is automatically copied and executed on worker nodes
# by start_cluster.sh via SSH. You should NOT run this script manually.
# Instead, run start_cluster.sh on the head node with WORKER_HOST set.
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# Configuration
IMAGE="${IMAGE:-nvcr.io/nvidia/vllm:25.11-py3}"
RAY_VERSION="${RAY_VERSION:-2.52.1}"
HF_CACHE="${HF_CACHE:-/raid/hf-cache}"
HF_TOKEN="${HF_TOKEN:-}"  # Set via: export HF_TOKEN=hf_xxx

# Model configuration - MUST match the head node's MODEL setting
MODEL="${MODEL:-openai/gpt-oss-120b}"

# Skip model download (set by head script when model is synced via rsync)
SKIP_MODEL_DOWNLOAD="${SKIP_MODEL_DOWNLOAD:-}"

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# Auto-detect Network Configuration
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# Uses ibdev2netdev to discover active InfiniBand/RoCE interfaces.
# The IP address on the IB/RoCE interface can be any valid IP (not limited
# to link-local addresses). We rely on ibdev2netdev output to identify the
# correct network interface for RDMA communication.
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# Discover primary RoCE/IB interface using ibdev2netdev
discover_ib_interface() {
  if command -v ibdev2netdev >/dev/null 2>&1; then
    # Get the first active (Up) interface from ibdev2netdev
    local active_line
    active_line=$(ibdev2netdev 2>/dev/null | awk '/\(Up\)/ {print; exit}')

    if [ -n "$active_line" ]; then
      # Extract interface name (5th field, removing parentheses)
      echo "$active_line" | awk '{print $5}' | tr -d '()'
    fi
  fi
}

# Get all active IB/RoCE HCAs (comma-separated for NCCL_IB_HCA)
discover_all_ib_hcas() {
  if command -v ibdev2netdev >/dev/null 2>&1; then
    ibdev2netdev 2>/dev/null | grep "(Up)" | awk '{print $1}' | sort | tr '\n' ',' | sed 's/,$//'
  fi
}

# Get the first IPv4 address from an interface
get_interface_ip() {
  local iface="$1"
  if [ -n "$iface" ]; then
    ip -o addr show "$iface" 2>/dev/null | grep "inet " | awk '{print $4}' | cut -d'/' -f1 | head -1
  fi
}

# Auto-detect primary IB/RoCE interface
PRIMARY_IB_IF=$(discover_ib_interface)

# HEAD_IP is required - must be provided (it's the head node's IB/RoCE IP)
if [ -z "${HEAD_IP:-}" ]; then
  echo ""
  echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
  echo "âŒ ERROR: HEAD_IP is not set"
  echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
  echo ""
  echo "âš ï¸  This script should be run automatically by start_cluster.sh on the head node."
  echo ""
  echo "To start the cluster with workers:"
  echo "  1. On the head node, set WORKER_HOST to the worker's InfiniBand IP"
  echo "  2. Run: bash start_cluster.sh"
  echo ""
  echo "The head node will automatically SSH to workers and start them."
  echo ""
  echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
  echo ""
  exit 1
fi

# Auto-detect WORKER_IP from IB interface (or use override)
if [ -z "${WORKER_IP:-}" ]; then
  if [ -n "${PRIMARY_IB_IF}" ]; then
    WORKER_IP=$(get_interface_ip "${PRIMARY_IB_IF}")
  fi
  # Final fallback if auto-detection fails
  if [ -z "${WORKER_IP:-}" ]; then
    echo "ERROR: Could not auto-detect WORKER_IP from InfiniBand/RoCE interface."
    echo ""
    echo "Please ensure:"
    echo "  1. The InfiniBand/RoCE cable is connected between nodes"
    echo "  2. Run 'ibdev2netdev' to verify IB/RoCE interfaces are Up"
    echo "  3. Check that an IP is assigned to the IB/RoCE interface"
    echo ""
    echo "Then either:"
    echo "  - Fix the interface and re-run this script, OR"
    echo "  - Set WORKER_IP manually: export WORKER_IP=<your_ib_ip>"
    exit 1
  fi
fi

# Auto-detect network interfaces from active IB/RoCE devices
if [ -z "${GLOO_IF:-}" ] || [ -z "${TP_IF:-}" ] || [ -z "${NCCL_IF:-}" ] || [ -z "${UCX_DEV:-}" ]; then
  if [ -n "${PRIMARY_IB_IF}" ]; then
    # Use primary IB interface for all NCCL/GLOO/TP/UCX communication
    GLOO_IF="${GLOO_IF:-${PRIMARY_IB_IF}}"
    TP_IF="${TP_IF:-${PRIMARY_IB_IF}}"
    NCCL_IF="${NCCL_IF:-${PRIMARY_IB_IF}}"
    UCX_DEV="${UCX_DEV:-${PRIMARY_IB_IF}}"
  else
    # Error if no IB interface detected and not manually specified
    echo "ERROR: No active InfiniBand/RoCE interface detected."
    echo "Run 'ibdev2netdev' to check interface status."
    exit 1
  fi
fi

# Auto-detect InfiniBand HCAs using ibdev2netdev (or use override)
if [ -z "${NCCL_IB_HCA:-}" ]; then
  IB_DEVICES=$(discover_all_ib_hcas)
  if [ -n "${IB_DEVICES}" ]; then
    NCCL_IB_HCA="${IB_DEVICES}"
  else
    # Fallback: use all IB devices from sysfs
    IB_DEVICES=$(ls -1 /sys/class/infiniband/ 2>/dev/null | tr '\n' ',' | sed 's/,$//')
    NCCL_IB_HCA="${IB_DEVICES:-}"
    if [ -z "${NCCL_IB_HCA}" ]; then
      echo "ERROR: No InfiniBand HCAs detected."
      echo "Run 'ibdev2netdev' or check /sys/class/infiniband/"
      exit 1
    fi
  fi
fi

# Set OMPI_MCA for MPI-based communication (needed for some frameworks)
OMPI_MCA_IF="${NCCL_IF}"

# Generate unique worker name based on hostname
WORKER_NAME="ray-worker-$(hostname -s)"

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

log() {
  echo "[$(date +'%Y-%m-%d %H:%M:%S')] $*"
}

error() {
  echo "[$(date +'%Y-%m-%d %H:%M:%S')] ERROR: $*" >&2
  exit 1
}

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

log "Starting DGX Spark vLLM Worker Setup"
log "Configuration:"
log "  Image:         ${IMAGE}"
log "  Worker Name:   ${WORKER_NAME}"
log "  Head IP:       ${HEAD_IP}"
log "  Worker IP:     ${WORKER_IP} (auto-detected)"
log "  Ray Version:   ${RAY_VERSION}"
log "  Model:         ${MODEL}"
log ""
if [ -n "${HF_TOKEN}" ]; then
  log "  HF Auth:       âœ… Token provided"
else
  log "  HF Auth:       âš ï¸  No token (gated models will fail)"
fi
log ""
log "Network Configuration (auto-detected from ibdev2netdev):"
log "  Primary IB IF:   ${PRIMARY_IB_IF:-<not detected>}"
log "  GLOO Interface:  ${GLOO_IF}"
log "  TP Interface:    ${TP_IF}"
log "  NCCL Interface:  ${NCCL_IF}"
log "  UCX Device:      ${UCX_DEV}"
log "  OMPI MCA IF:     ${OMPI_MCA_IF}"
log "  NCCL IB HCAs:    ${NCCL_IB_HCA}"
log ""

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

log "Step 1/8: Testing connectivity to head"
if ! nc -zv -w 3 "${HEAD_IP}" 6380 2>&1 | grep -q "succeeded"; then
  error "Cannot reach Ray head at ${HEAD_IP}:6380. Check network connectivity and firewall."
fi
log "  âœ… Head is reachable"

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

log "Step 2/8: Pulling Docker image"
if ! docker pull "${IMAGE}"; then
  error "Failed to pull image ${IMAGE}"
fi

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

log "Step 3/8: Cleaning old container"
if docker ps -a --format '{{.Names}}' | grep -qx "${WORKER_NAME}"; then
  log "  Removing existing container: ${WORKER_NAME}"
  docker rm -f "${WORKER_NAME}" >/dev/null
fi

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

log "Step 4/8: Starting worker container"

# Build environment variable args for IB/NCCL configuration
# These are passed into the container to ensure NCCL uses the IB/RoCE link
# Note: We do NOT set HF_HUB_OFFLINE=1 because we need to download model weights first

# Build HF token env arg if provided
HF_TOKEN_ENV=""
if [ -n "${HF_TOKEN}" ]; then
  HF_TOKEN_ENV="-e HF_TOKEN=${HF_TOKEN}"
fi

# Run container as root (required for NVIDIA/vLLM)
docker run -d \
  --restart unless-stopped \
  --name "${WORKER_NAME}" \
  --gpus all \
  --network host \
  --shm-size=16g \
  --ulimit memlock=-1 \
  --ulimit stack=67108864 \
  --cap-add=SYS_NICE \
  --device=/dev/infiniband \
  -v "${HF_CACHE}:/root/.cache/huggingface" \
  -e VLLM_HOST_IP="${WORKER_IP}" \
  -e GLOO_SOCKET_IFNAME="${GLOO_IF}" \
  -e TP_SOCKET_IFNAME="${TP_IF}" \
  -e NCCL_SOCKET_IFNAME="${NCCL_IF}" \
  -e UCX_NET_DEVICES="${UCX_DEV}" \
  -e OMPI_MCA_btl_tcp_if_include="${OMPI_MCA_IF}" \
  -e NCCL_IB_DISABLE=0 \
  -e NCCL_IB_HCA="${NCCL_IB_HCA}" \
  -e NCCL_NET_GDR_LEVEL=5 \
  -e NCCL_DEBUG="${NCCL_DEBUG:-INFO}" \
  -e NCCL_DEBUG_SUBSYS="${NCCL_DEBUG_SUBSYS:-INIT,NET}" \
  -e NVIDIA_VISIBLE_DEVICES=all \
  -e NVIDIA_DRIVER_CAPABILITIES=all \
  -e RAY_memory_usage_threshold=0.995 \
  -e HF_HOME=/root/.cache/huggingface \
  -e FST_USE_GDS=0 \
  ${HF_TOKEN_ENV} \
  "${IMAGE}" sleep infinity

if ! docker ps | grep -q "${WORKER_NAME}"; then
  error "Container failed to start"
fi

log "  Container started successfully"

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

log "Step 5/8: Verifying RDMA/InfiniBand libraries for NCCL"
log "  These libraries are required for NCCL to use InfiniBand/RoCE instead of Ethernet"
# NVIDIA vLLM container already includes RDMA libraries (libibverbs, librdmacm, ibverbs-providers)
# We just verify they're present rather than installing
if docker exec "${WORKER_NAME}" bash -lc "ldconfig -p 2>/dev/null | grep -q libibverbs"; then
  log "  âœ… RDMA libraries available (libibverbs, librdmacm)"
else
  log "  âš ï¸  Warning: RDMA libraries may not be properly installed"
  log "     NCCL may fall back to Socket transport (slower)"
fi

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

log "Step 6/8: Verifying container dependencies"
# The nvidia vLLM container already has vLLM and Ray properly built
# Do NOT pip install vllm as it would overwrite the CUDA-enabled version with CPU-only PyPI version

# Verify vLLM is available with CUDA
CUDA_AVAILABLE=$(docker exec "${WORKER_NAME}" python3 -c "import torch; print(torch.cuda.is_available())" 2>/dev/null || echo "False")
if [ "${CUDA_AVAILABLE}" != "True" ]; then
  error "PyTorch CUDA not available - container may be corrupted. Try: docker pull nvcr.io/nvidia/vllm:25.11-py3"
fi
log "  âœ… PyTorch CUDA available"

INSTALLED_VLLM_VERSION=$(docker exec "${WORKER_NAME}" python3 -c "import vllm; print(vllm.__version__)" 2>/dev/null || echo "unknown")
if [ "${INSTALLED_VLLM_VERSION}" == "unknown" ]; then
  error "vLLM not found in container"
fi
log "  âœ… vLLM ${INSTALLED_VLLM_VERSION} available"

# Verify Ray version
INSTALLED_RAY_VERSION=$(docker exec "${WORKER_NAME}" python3 -c "import ray; print(ray.__version__)" 2>/dev/null || echo "unknown")
if [ "${INSTALLED_RAY_VERSION}" == "unknown" ]; then
  error "Ray not found in container"
fi
log "  âœ… Ray ${INSTALLED_RAY_VERSION} available"

# Install only fastsafetensors if not already present (does not affect vLLM/PyTorch)
if ! docker exec "${WORKER_NAME}" python3 -c "import fastsafetensors" 2>/dev/null; then
  log "  Installing fastsafetensors..."
  # Unset PIP_CONSTRAINT to avoid deprecation warning from nvidia container
  docker exec "${WORKER_NAME}" bash -lc "unset PIP_CONSTRAINT && pip install -q --root-user-action=ignore fastsafetensors" || true
fi
log "  fastsafetensors available"

# Apply fastsafetensors cluster patch (fixes device group handling in distributed setup)
# See: https://github.com/foundation-model-stack/fastsafetensors/issues/36
# The patch content is embedded here since this script runs on the worker node
PATCH_CONTENT='diff --git a/vllm/model_executor/model_loader/weight_utils.py b/vllm/model_executor/model_loader/weight_utils.py
--- a/vllm/model_executor/model_loader/weight_utils.py
+++ b/vllm/model_executor/model_loader/weight_utils.py
@@ -28,6 +28,7 @@ from vllm import envs
 from vllm.config import ModelConfig
 from vllm.config.load import LoadConfig
 from vllm.distributed import get_tensor_model_parallel_rank
+from vllm.distributed.parallel_state import get_world_group
 from vllm.logger import init_logger
 from vllm.model_executor.layers.quantization import (QuantizationConfig,
                                                      get_quantization_config)
@@ -647,11 +648,16 @@ def fastsafetensors_weights_iterator(
     """Iterate over the weights in the model safetensor files
     using fastsafetensor library."""
     if torch.distributed.is_initialized():
-        pg = torch.distributed.group.WORLD
+        world = get_world_group()
+        pg = world.device_group
+        device = world.device
     else:
         pg = SingleGroup()
+        device = torch.device(f'"'"'cuda:{pg.rank()}'"'"')

-    device = torch.device(f"cuda:{pg.rank()}")
+    # Disable GDS by default (use POSIX) unless FST_USE_GDS=1 is set
+    # GDS requires special driver/filesystem support not available everywhere
+    use_gds = os.environ.get('"'"'FST_USE_GDS'"'"', '"'"'0'"'"') == '"'"'1'"'"'
     weight_files_sub_lists = [
         hf_weights_files[i:i + pg.size()]
         for i in range(0, len(hf_weights_files), pg.size())
@@ -665,7 +671,7 @@ def fastsafetensors_weights_iterator(
             disable=not enable_tqdm(use_tqdm_on_load),
             bar_format=_BAR_FORMAT,
     ):
-        loader = SafeTensorsFileLoader(pg, device)
+        loader = SafeTensorsFileLoader(pg, device, nogds=not use_gds)
         rank_file_map = {i: [f] for i, f in enumerate(f_list)}
         loader.add_filenames(rank_file_map)
         try:'

log "  Applying fastsafetensors cluster patch..."
if docker exec "${WORKER_NAME}" bash -c "
  echo '${PATCH_CONTENT}' > /tmp/fastsafetensors.patch
  cd /usr/local/lib/python3.12/dist-packages && \
  patch -p1 --forward < /tmp/fastsafetensors.patch 2>/dev/null || \
  patch -p1 --forward -d /opt/vllm < /tmp/fastsafetensors.patch 2>/dev/null || \
  echo 'Patch may already be applied or path differs'
"; then
  log "  âœ… fastsafetensors cluster patch applied"
else
  log "  âš ï¸  Could not apply fastsafetensors patch (may already be applied)"
fi

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

if [ -n "${SKIP_MODEL_DOWNLOAD}" ]; then
  log "Step 7/8: Verifying model weights (synced from head)"
  log "  Model: ${MODEL}"
  log "  Skipping download - model was synced from head node via rsync"

  # Verify model was synced by checking for config.json
  if ! docker exec "${WORKER_NAME}" bash -lc "
    export HF_HOME=/root/.cache/huggingface
    python3 -c \"
from huggingface_hub import snapshot_download
import os
path = snapshot_download('${MODEL}', local_files_only=True)
config_path = os.path.join(path, 'config.json')
if not os.path.exists(config_path):
    raise FileNotFoundError(f'Model config not found at {config_path}')
print(f'  âœ… Model verified at: {path}')
\"
  "; then
    error "Model verification failed - model may not have been synced correctly from head"
  fi

  log "  Model verification complete"
else
  log "Step 7/8: Pre-downloading model weights"
  log "  Model: ${MODEL}"
  log "  This may take a while for large models on first download..."
  log ""
  log "  âš ï¸  IMPORTANT: This model MUST match the head node's MODEL setting!"
  log ""

  # Build HF token arg if provided
  HF_TOKEN_ARG=""
  if [ -n "${HF_TOKEN}" ]; then
    HF_TOKEN_ARG="--token ${HF_TOKEN}"
  fi

  # Download model with verification (using 'hf download' instead of deprecated 'huggingface-cli download')
  if ! docker exec "${WORKER_NAME}" bash -lc "
    export HF_HOME=/root/.cache/huggingface
    echo '  Downloading model files (excluding original/* and metal/* to save space)...'
    hf download ${MODEL} ${HF_TOKEN_ARG} --exclude 'original/*' --exclude 'metal/*' 2>&1 | tail -5
  "; then
    error "Failed to download model ${MODEL}"
  fi

  # Verify model was downloaded by checking for config.json
  if ! docker exec "${WORKER_NAME}" bash -lc "
    export HF_HOME=/root/.cache/huggingface
    python3 -c \"
from huggingface_hub import snapshot_download
import os
path = snapshot_download('${MODEL}', local_files_only=True)
config_path = os.path.join(path, 'config.json')
if not os.path.exists(config_path):
    raise FileNotFoundError(f'Model config not found at {config_path}')
print(f'  âœ… Model verified at: {path}')
\"
  "; then
    error "Model verification failed - config.json not found"
  fi

  log "  Model download complete and verified"
fi

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

log "Step 8/8: Joining Ray cluster"
docker exec "${WORKER_NAME}" bash -lc "
  ray stop --force 2>/dev/null || true
  ray start --address=${HEAD_IP}:6380 --node-ip-address=${WORKER_IP}
" >/dev/null

log "  Worker started, waiting for cluster registration..."

# Wait for worker to join cluster with progress indicator
# Check for multiple nodes in the cluster (more reliable than "Healthy:" which may not appear immediately)
START_TIME=$(date +%s)
CONNECTED=false
for i in {1..60}; do
  CURRENT_TIME=$(date +%s)
  ELAPSED=$((CURRENT_TIME - START_TIME))

  # Check if ray status shows more than 1 node (head + this worker)
  NODE_COUNT=$(docker exec "${WORKER_NAME}" bash -lc "ray status --address=${HEAD_IP}:6380 2>/dev/null | grep -E '^ [0-9]+ node_' | wc -l" 2>/dev/null || echo "0")
  if [ "${NODE_COUNT}" -ge 2 ]; then
    echo ""
    log "  âœ… Worker connected to cluster (${ELAPSED}s) - ${NODE_COUNT} nodes active"
    CONNECTED=true
    break
  fi

  # Show spinner
  SPINNER="â ‹â ™â ¹â ¸â ¼â ´â ¦â §â ‡â "
  SPIN_CHAR="${SPINNER:$((i % 10)):1}"
  printf "\r  %s Connecting to Ray cluster... [%ds elapsed]  " "${SPIN_CHAR}" "${ELAPSED}"

  sleep 1
done

if [ "${CONNECTED}" != "true" ]; then
  echo ""
  log "  âš ï¸  Connection check timed out after 60s"
  log "     The worker may still be connected - verify from head node:"
  log "     docker exec ray-head ray status --address=127.0.0.1:6380"
fi

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

echo ""
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "âœ… Worker ${WORKER_NAME} is ready!"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo ""
echo "ğŸ” Verify from head node:"
echo "  docker exec ray-head ray status --address=127.0.0.1:6380"
echo ""
echo "ğŸ“Š Expected output should show multiple 'Healthy' nodes"
echo ""
echo "ğŸŒ Ray Dashboard: http://${HEAD_IP}:8265"
echo "   (Check 'Cluster' tab to see all nodes)"
echo ""
echo "âš™ï¸  To increase parallelism, update head vLLM with:"
echo "  --tensor-parallel-size <num_total_gpus>"
echo ""
echo "ğŸ”§ Worker logs:"
echo "  docker logs -f ${WORKER_NAME}"
echo ""
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
